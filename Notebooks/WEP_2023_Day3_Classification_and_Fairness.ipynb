{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcmepKAf7t_d"
   },
   "source": [
    "# WEP Lecture 3\n",
    "\n",
    "# Part 1. Classification\n",
    "\n",
    "In the first part we will try to classify handwritten digits by using multiple Machine Learning methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpGOCc2W7t_s"
   },
   "source": [
    "**1.1 Looking at the data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FH5nPaT87t_p"
   },
   "outputs": [],
   "source": [
    "#Import useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxs0XGca7t_u"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mnist_data = pd.read_csv('sample_data/mnist_train_small.csv').values\n",
    "mnist_data = pd.DataFrame(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aI3R-0UR7t_w"
   },
   "outputs": [],
   "source": [
    "# TODO: How many examples are present in the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28itbSt0j49V"
   },
   "outputs": [],
   "source": [
    "# Show the the first 5 rows of the data using the head()-function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yIV4j1Lltfe"
   },
   "outputs": [],
   "source": [
    "# TODO: Print one instance from the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyAji3Cy7t_0"
   },
   "outputs": [],
   "source": [
    "# TODO: Show the number of times each digit is in the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNIUYVNI7t_1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here we split the the data into the labels and the features\n",
    "digits = mnist_data[0]\n",
    "pixels = mnist_data.drop(0, axis=1)\n",
    "print(\"Shape of labels = \", np.shape(digits))\n",
    "print(\"Shape of features = \", np.shape(pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiBRi3uv7t_2"
   },
   "outputs": [],
   "source": [
    "# This output shows you the label and the pixel values of an example image. \n",
    "plt.imshow(pixels.loc[0].values.reshape(28,28))\n",
    "plt.show()\n",
    "print(\"Label = \", digits[0])\n",
    "print(\"Pixel values = \", pixels.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5adFa-TC7t_3"
   },
   "source": [
    "**1.2 Create train and test set**\n",
    "\n",
    "In the next step we will split the data into a train set and a test set. We will use sklearn's function called 'train_test_split'. We want the train set to be 70% of the data, and the test set 30%. Look at the documentation https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html and try to find out what needs to be filled in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ew_3xesg7t_4"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: split the data into training and testing \n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOH2g0R37t_5"
   },
   "outputs": [],
   "source": [
    "# Check: do the datasets have the correct shape?\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVgqR1CO7t_5"
   },
   "source": [
    "**1.3 Logistic Regression**\n",
    "\n",
    "Now we can create a Logistic Regression classifier. We will use LogisticRegression(solver='saga'). You can leave other parameters to their default values. Instantiate the classifier, fit the model and make a prediction.\n",
    "\n",
    "You can look at the documentation for more information https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjBMYrGd7t_6"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# TODO: Instantiate the classifier, fit the model and make a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Z8c31gJ7t_7"
   },
   "source": [
    "To evaluate the performance of the classifier we can look at the accuracy. Look at the documentation for the accuracy score https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfIqf-eL7t_7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# TODO: Calculate the accuracy\n",
    "accuracy1 =      \n",
    "print(\"Accuracy = \", accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJWZJragiwhA"
   },
   "source": [
    "Plot the confusion matrix to see how often the digits get classified correctly, and which mistakes are made. You can use confusion_matrix (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix. Try to determine which digits often get mistaken for each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipFtBP-hzw3O"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# TODO: Create the confusion matrix\n",
    "cm1 = \n",
    "\n",
    "#Which digits get often confused for each other?\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm1)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS_NUENZ0VC2"
   },
   "source": [
    "**1.4 Random Forest**\n",
    "\n",
    "Similar to the Logistic Regression classifier, we can make a Random Forest classifier. \n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNO4ahX77t_8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# TODO: Instantiate the classifier, fit the model and make a prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsY_wafE7t_8"
   },
   "outputs": [],
   "source": [
    "# TODO: compute the accuracy of the RF model\n",
    "accuracy2 = \n",
    "print(\"Accuracy = \", accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0-VOQGr1ibW"
   },
   "outputs": [],
   "source": [
    "# TODO: Create the confusion matrix\n",
    "cm2 = \n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm2)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n88wb0I-110t"
   },
   "source": [
    "**1.5 Neural Network**\n",
    "\n",
    "Finally, we will train a neural network for the classification task. We will use a Multi-Layer Perceptron classifier.\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwMMszLe7t_9"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# TODO: Instantiate the classifier, fit the model and make a prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxB8eEUC7t_9"
   },
   "outputs": [],
   "source": [
    "# TODO: compute the accuracy of the NN model\n",
    "accuracy3 = \n",
    "print(\"Accuracy = \", accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNXjtc-D2Xyv"
   },
   "outputs": [],
   "source": [
    "# TODO: Create the confusion matrix\n",
    "cm3 = \n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm3)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKB80Z-3rIfi"
   },
   "source": [
    "Optional: Take a look at the documentation for the performance metrics: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vm702YWqgYH"
   },
   "outputs": [],
   "source": [
    "# Optional: can you find other performance metrics and apply them to the classifier?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1YqSNRe7t_9"
   },
   "source": [
    "# Part 2\n",
    "\n",
    "In this part we will look at the COMPAS dataset. Run the cells below to get ready to work with fairness!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heiiDrOe8FD7"
   },
   "source": [
    "**2.1 Loading the data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqmC3zi47t_-"
   },
   "outputs": [],
   "source": [
    "#Run this cell to install the required packages\n",
    "!pip install aif360\n",
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbDx5OXo8TQc"
   },
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_compas\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2He4xOv7t_-"
   },
   "outputs": [],
   "source": [
    "#Run this cell to load the data\n",
    "!wget -c https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
    "!mv compas-scores-two-years.csv /usr/local/lib/python3.7/dist-packages/aif360/data/raw/compas\n",
    "\n",
    "compas_data = load_preproc_data_compas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk93vgUXrYZE"
   },
   "source": [
    "**2.2 Looking at the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dWXbfSi8SXz"
   },
   "outputs": [],
   "source": [
    "# TODO: What features are used?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyW4AhOT-TBc"
   },
   "outputs": [],
   "source": [
    "# TODO: What is the label, and what does the label mean?\n",
    "label = \n",
    "unfav = \n",
    "fav = \n",
    "print(\"Label = \", label)\n",
    "print(\"Favorable label = \", unfav)\n",
    "print(\"Unfavorable label = \", fav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsW4Ja10rxiH"
   },
   "source": [
    "In the data, sex is divided in 0 = men, and 1 = women. Race is divided into 0 = African-American, and 1 = Caucasian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8LoB7Mio0Au"
   },
   "outputs": [],
   "source": [
    "#What do you notice in the distribution of the data?\n",
    "compas_data.convert_to_dataframe()[0].groupby(['race','sex','two_year_recid'])['two_year_recid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9wgfbDso0Ro"
   },
   "outputs": [],
   "source": [
    "priv_group   = [{'race': 1, 'sex' : 1}]  # Caucasian woman\n",
    "unpriv_group = [{'race': 0, 'sex': 0}]  # African-American man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOS14Xezo_cy"
   },
   "outputs": [],
   "source": [
    "#The base rate tells you the percentage of positive outcomes. What do you notice?\n",
    "metric_orig = BinaryLabelDatasetMetric(compas_data, unprivileged_groups=unpriv_group, privileged_groups=priv_group)\n",
    "print(\"Percentage of positive outcomes for the unprivileged group = %f\" % metric_orig.base_rate(False)) \n",
    "print(\"Percentage of positive outcomes for the privileged group = %f\" % metric_orig.base_rate(True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCO3CdtLuYzr"
   },
   "source": [
    "**2.3 Creating a classifier**\n",
    "\n",
    "We have looked at the original data. But what happens if we train a classifier on this biased data set?\n",
    "\n",
    "Start by splitting the data in a train and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAdMNQgCvfik"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = compas_data.split([0.8], shuffle=True)\n",
    "X_train = train_data.features\n",
    "y_train = train_data.labels.ravel()\n",
    "X_test = test_data.features\n",
    "y_test = test_data.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRmOAo6v8FtY"
   },
   "source": [
    "We will look at the base rates in the train and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prz6qetZ3rmz"
   },
   "outputs": [],
   "source": [
    "#Train data\n",
    "metric_train = BinaryLabelDatasetMetric(train_data, unprivileged_groups=unpriv_group, privileged_groups=priv_group)\n",
    "print(\"Percentage of positive outcomes for the unprivileged group = %f\" % metric_train.base_rate(False)) \n",
    "print(\"Percentage of positive outcomes for the privileged group = %f\" % metric_train.base_rate(True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxMZYB9w3fwe"
   },
   "outputs": [],
   "source": [
    "#Test data\n",
    "metric_test = BinaryLabelDatasetMetric(test_data, unprivileged_groups=unpriv_group, privileged_groups=priv_group)\n",
    "print(\"Percentage of positive outcomes for the unprivileged group = %f\" % metric_test.base_rate(False)) \n",
    "print(\"Percentage of positive outcomes for the privileged group = %f\" % metric_test.base_rate(True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwbtt0UuvwGR"
   },
   "outputs": [],
   "source": [
    "# TODO: build a classifier\n",
    "clf_compas = \n",
    "# TODO: Fit the classifier\n",
    "\n",
    "\n",
    "pred_compas = test_data.copy(deepcopy = True)\n",
    "pred_compas.labels = ##TO DO: predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3K2ZWwX2wFeT"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy = \", accuracy_score(y_test, pred_compas.labels))\n",
    "cm = confusion_matrix(y_test, pred_compas.labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EdqXWyxzOoS"
   },
   "outputs": [],
   "source": [
    "#Now look at the percentage of positive outcomes for both groups in the predictions. What happened?\n",
    "metric2 = BinaryLabelDatasetMetric(pred_compas, unprivileged_groups=unpriv_group, privileged_groups=priv_group)\n",
    "print(\"Percentage of positive outcomes for the unprivileged group = %f\" % metric2.base_rate(False)) \n",
    "print(\"Percentage of positive outcomes for the privileged group = %f\" % metric2.base_rate(True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXVVi3yfuFJ-"
   },
   "source": [
    "# Part 3\n",
    "\n",
    "In the final part we will look at the fairness of the classifier trained on the COMPAS data set. We create a Classification Metric, and use its methods to calculate multiple fairness measures.\n",
    "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.metrics.ClassificationMetric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ImyOep_7b_o"
   },
   "outputs": [],
   "source": [
    "#We create a Classification metric\n",
    "fairness_metric = ClassificationMetric(test_data, pred_compas, unprivileged_groups= unpriv_group, privileged_groups= priv_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-J1KyVhuQdz"
   },
   "outputs": [],
   "source": [
    "#Calculate the Statistical Parity difference and the Disparate Impact (ratio)\n",
    "statistical_parity_difference = ##TO DO\n",
    "disparate_impact = ##TO DO\n",
    "print(\"statistical parity difference =\", statistical_parity_difference)\n",
    "print(\"disparate impact =\", disparate_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ktPzZ-462nx"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate the True Positive Rate for the privileged and the unprivileged group, and their difference\n",
    "TPR_priv = \n",
    "TPR_unpriv = \n",
    "TPR_difference = \n",
    "print(\"TPR (priv_group) =\", TPR_priv) #TPR for privileged group\n",
    "print(\"TPR (unpriv_group) =\", TPR_unpriv) #TPR for unprivileged group\n",
    "print(\"TPR difference =\", TPR_difference) #TPR difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcOUBCRo7Aca"
   },
   "outputs": [],
   "source": [
    "# TODO: Use the consistency metric to calculate individual fairness\n",
    "consistency = \n",
    "print(\"Individual fairness metric that measures how similar the labels are for similar instances = %f\" % consistency)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "WEP_Lecture_3_Classification_and_Fairness.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
